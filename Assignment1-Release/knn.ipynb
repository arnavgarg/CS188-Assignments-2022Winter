{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcJK3kXl--c3"
   },
   "source": [
    "# CS188 Assignment 1-2: K-Nearest Neighbors (k-NN) \n",
    "\n",
    "Before we start, please put your name and UD in following format\n",
    "\n",
    ": Firstname LASTNAME, #00000000   //   e.g.) Yining Hong, #000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sA2iBcm_cPb"
   },
   "source": [
    "**Your Answer:**   \n",
    "Your NAME, #XXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EylwToVNld4u"
   },
   "source": [
    "In this notebook you will implement a K-Nearest Neighbors classifier on the TinyPlaces dataset you created.\n",
    "\n",
    "Recall that the K-Nearest Neighbor classifier does the following:\n",
    "- During training, the classifier simply memorizes the training data\n",
    "- During testing, test images are compared to each training image; the predicted label is the majority vote among the K nearest training examples.\n",
    "\n",
    "After implementing the K-Nearest Neighbor classifier, you will use *cross-validation* to find the best value of K.\n",
    "\n",
    "You will first focus on binary classification, then we will switch to multi-class classification.\n",
    "\n",
    "You will first use raw pixel values as inputs, and then play with feature extraction. \n",
    "\n",
    "Since the test set of MiniPlaces is not public, and in this script we use cross-validation (so we do not need a validation set). Therefore, we use the validation set that we prepared for testing.  \n",
    "\n",
    "The goals of this exercise are to go through a simple example of the data-driven image classification pipeline, and also to practice writing efficient, vectorized code in [PyTorch](https://pytorch.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrEwOpXb9Gh"
   },
   "source": [
    "# Setup Code\n",
    "Before getting started we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook.\n",
    "\n",
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73cuTs3re6wg"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnf0BfHZfWzO"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1640850386333,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "VxbQtNB6fWzO",
    "outputId": "d6b0ab18-1fa6-4f3b-991e-72c0dee86f9c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1640850387718,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "kfzFXbiEfWzS",
    "outputId": "d6cfd78b-7a0e-416c-b77c-68c4d6eab155"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
    "# Example: If you create a 188 folder and put all the files under A1 folder, then '188/Assignment1'\n",
    "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '188/Assignment1'\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Assignment1'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY_PV4eQfWzU"
   },
   "source": [
    "Once you have successfully mounted your Google Drive and located the path to this assignment, run th following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n",
    "\n",
    "```\n",
    "Hello from knn.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the file `pytorch101.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3612,
     "status": "ok",
     "timestamp": 1640850394267,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "VGbUf6nTfWzV",
    "outputId": "0305cbd6-3d07-45fb-b09b-5a84908c27cc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "import time, os\n",
    "os.environ[\"TZ\"] = \"US/Eastern\"\n",
    "time.tzset()\n",
    "\n",
    "from knn import hello\n",
    "hello()\n",
    "\n",
    "knn_path = os.path.join(GOOGLE_DRIVE_PATH, 'knn.py')\n",
    "knn_edit_time = time.ctime(os.path.getmtime(knn_path))\n",
    "print('knn.py last edited on %s' % knn_edit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emQnvtnFeX1H"
   },
   "source": [
    "## Setup code\n",
    "Run some setup code for this notebook: Import some useful packages and increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tf64a0TS8zh7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cs188\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M0pmnWwgFu5"
   },
   "source": [
    "# K-Nearest Neighbors (k-NN) Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOZTkdiSmUFc"
   },
   "source": [
    "## Compute distances: Naive implementation\n",
    "Now that we have examined and prepared our data, it is time to implement the kNN classifier. We can break the process down into two steps:\n",
    "\n",
    "1. Compute the (squared Euclidean) distances between all training examples and all test examples\n",
    "2. Given these distances, for each test example find its k nearest neighbors and have them vote for the label to output\n",
    "\n",
    "Lets begin with computing the distance matrix between all training and test examples. First we will implement a naive version of the distance computation, using explicit loops over the training and test sets. In the file `knn.py`, implement the function `compute_distances_two_loops`.\n",
    "\n",
    "**NOTE: When implementing distance functions for this assignment, you may not use functions `torch.norm` or `torch.dist` (or their instance method variants `x.norm` / `x.dist`); you may not use any functions from `torch.nn` or `torch.nn.functional`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1800,
     "status": "ok",
     "timestamp": 1640850453476,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "oHq2bs_MnqVM",
    "outputId": "41c851d2-5048-4051-c7be-5034a5036eb7"
   },
   "outputs": [],
   "source": [
    "from knn import compute_distances_two_loops\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "dists = compute_distances_two_loops(x_train, x_test)\n",
    "print('dists has shape: ', dists.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGdFIqBEpPcQ"
   },
   "source": [
    "As a visual debugging step, we can visualize the distance matrix, where each row is a test example and each column is a training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1640850457474,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "dshO3kmOKk0T",
    "outputId": "25519a89-4cab-4545-8dc1-2d0db76698d2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(dists.numpy(), cmap='gray', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xlabel('test')\n",
    "plt.ylabel('train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHkuvdr_1HqC"
   },
   "source": [
    "## Compute distances: Vectorization\n",
    "Our implementation of the distance computation above is fairly inefficient since it uses nested Python loops over the training and test sets.\n",
    "\n",
    "When implementing algorithms in PyTorch, it's best to avoid loops in Python if possible. Instead it is preferable to implement your computation so that all loops happen inside PyTorch functions. This will usually be much faster than writing your own loops in Python, since PyTorch functions can be internally optimized to iterate efficiently, possibly using multiple threads. This is especially important when using a GPU to accelerate your code.\n",
    "\n",
    "The process of eliminating explict loops from your code is called **vectorization**. Sometimes it is straighforward to vectorize code originally written with loops; other times vectorizing requires thinking about the problem in a new way. We will use vectorization to improve the speed of our distance computation function.\n",
    "\n",
    "As a first step toward vectorizing our distance computation, you will implement a version that uses only a single Python loop over the training data. In the file `knn.py`, complete the implementation of the function `compute_distances_one_loop`.\n",
    "\n",
    "We can check the correctness of our one-loop implementation by comparing it with our two-loop implementation on some randomly generated data.\n",
    "\n",
    "Note that we do the comparison with 64-bit floating points for increased numeric precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1640850466415,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "ujU8bWch4EmK",
    "outputId": "de7afd3d-6eda-4fff-e1fb-494e57a31c6d"
   },
   "outputs": [],
   "source": [
    "from knn import compute_distances_one_loop\n",
    "from knn import compute_distances_two_loops\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "x_test_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "\n",
    "dists_one = compute_distances_one_loop(x_train_rand, x_test_rand)\n",
    "dists_two = compute_distances_two_loops(x_train_rand, x_test_rand)\n",
    "difference = (dists_one - dists_two).pow(2).sum().sqrt().item()\n",
    "print('Difference: ', difference)\n",
    "if difference < 1e-4:\n",
    "    print('Good! The distance matrices match')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqtIsY6x_kb9"
   },
   "source": [
    "You will now implement a fully vectorized version of the distance computation function\n",
    "that does not use any Python loops. In the file `knn.py`, implement the function `compute_distances_no_loops`.\n",
    "\n",
    "As before, we can check the correctness of our implementation by comparing the fully vectorized version against the original naive version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1640850509498,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "1RY8QBeS9WYK",
    "outputId": "ae414ebe-02cf-4707-dd57-2e8dfb494811"
   },
   "outputs": [],
   "source": [
    "from knn import compute_distances_two_loops\n",
    "from knn import compute_distances_no_loops\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "x_test_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "\n",
    "dists_two = compute_distances_two_loops(x_train_rand, x_test_rand)\n",
    "dists_none = compute_distances_no_loops(x_train_rand, x_test_rand)\n",
    "difference = (dists_two - dists_none).pow(2).sum().sqrt().item()\n",
    "print('Difference: ', difference)\n",
    "if difference < 1e-4:\n",
    "  print('Good! The distance matrices match')\n",
    "else:\n",
    "  print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JPMM0-BBGmt"
   },
   "source": [
    "We can now compare the speed of our three implementations. If you've implemented everything properly, the one-loop implementation should take less than 4 seconds to run, and the fully vectorized implementation should take less than 0.1 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10448,
     "status": "ok",
     "timestamp": 1640850522754,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "IN9cntDC5c5q",
    "outputId": "5a73371a-e371-4548-8a03-aa1e5b154e20"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from knn import compute_distances_two_loops\n",
    "from knn import compute_distances_one_loop\n",
    "from knn import compute_distances_no_loops\n",
    "\n",
    "def timeit(f, *args):\n",
    "    tic = time.time()\n",
    "    f(*args) \n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train_rand = torch.randn(500, 3, 32, 32)\n",
    "x_test_rand = torch.randn(500, 3, 32, 32)\n",
    "\n",
    "two_loop_time = timeit(compute_distances_two_loops, x_train_rand, x_test_rand)\n",
    "print('Two loop version took %.2f seconds' % two_loop_time)\n",
    "\n",
    "one_loop_time = timeit(compute_distances_one_loop, x_train_rand, x_test_rand)\n",
    "speedup = two_loop_time / one_loop_time\n",
    "print('One loop version took %.2f seconds (%.1fX speedup)'\n",
    "      % (one_loop_time, speedup))\n",
    "\n",
    "no_loop_time = timeit(compute_distances_no_loops, x_train_rand, x_test_rand)\n",
    "speedup = two_loop_time / no_loop_time\n",
    "print('No loop version took %.2f seconds (%.1fX speedup)'\n",
    "      % (no_loop_time, speedup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EudsSj5TrGGF"
   },
   "source": [
    "## Predict labels\n",
    "Now that we have a method for computing distances between training and test examples, we need to implement a function that uses those distances together with the training labels to predict labels for test samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PJSbsyO6B3J"
   },
   "source": [
    "#### Image Retrieval\n",
    "\n",
    "We first implement the function that retrieves the indices of top k relevant images. In the file `knn.py`, implement the function `predict_labels` to output indices first. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkalOmS-CeVJ"
   },
   "source": [
    "We first work on a toy example of 1D data to test `predict_labels` to output the correct indices. If your implementation is correct, should output tensor([[1, 2, 0]])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1640850565502,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "kEDVPDatCniR",
    "outputId": "71536b30-e769-47bf-da01-f7f47f0c6abd"
   },
   "outputs": [],
   "source": [
    "from knn import predict_labels\n",
    "\n",
    "torch.manual_seed(0)\n",
    "dists = torch.tensor([\n",
    "    [0.3, 0.4, 0.1],\n",
    "    [0.1, 0.5, 0.5],\n",
    "    [0.4, 0.1, 0.2],\n",
    "    [0.2, 0.2, 0.4],\n",
    "    [0.5, 0.3, 0.3],\n",
    "])\n",
    "y_train = torch.tensor([0, 1, 0, 1, 2])\n",
    "indices, _ = predict_labels(dists, y_train, k=1)\n",
    "print (indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BByeHVlnCbC5"
   },
   "source": [
    "Then we implement the `retrieval` function in `KnnClassifier` to retrieve 2D images. We use an example from the TinyPlaces dataset. We visualize the 5 most relevant images from the training dataset giving a sample from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1640853873294,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "IkS1SRmt76uO",
    "outputId": "eea0d12e-6033-4d4c-c625-342d2fefb86d"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "\n",
    "num_classes = 2\n",
    "classes_list = ['indoor', 'outdoor']\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "\n",
    "indices = classifier.retrieval(x_test[:1], k=5)\n",
    "\n",
    "print (\"this is the original sample from the test set of %s scene\"%classes_list[y_test[0]])\n",
    "plt.imshow(cs188.tensor_to_image(x_test[0]))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "for idx in indices:\n",
    "  samples.append(x_train[idx].squeeze())\n",
    "  labels.append(y_train[idx].squeeze())\n",
    "\n",
    "\n",
    "print (\"this is the most relevant images from the training set to an %s sample\"%classes_list[y_test[0]])\n",
    "img = torchvision.utils.make_grid(samples, nrow=5)\n",
    "plt.imshow(cs188.tensor_to_image(img))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print (\"and their labels\")\n",
    "print ([classes_list[label] for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plk1KP0KBf6K"
   },
   "source": [
    "If your implementation is right, you should see that most of the images belong to the same group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOA45gZIDiQL"
   },
   "source": [
    "#### Predict Labels\n",
    "The next step is to output the labels via retrieved indices. We further implement `predict_labels` to output the labels for an example in the test set. Here we use a toy test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1640850751420,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "wO58y5L7DvOM",
    "outputId": "5175c94b-21b4-4c87-d75c-abc2c82463fa"
   },
   "outputs": [],
   "source": [
    "from knn import predict_labels\n",
    "\n",
    "torch.manual_seed(0)\n",
    "dists = torch.tensor([\n",
    "    [0.3, 0.4, 0.1],\n",
    "    [0.1, 0.5, 0.5],\n",
    "    [0.4, 0.1, 0.2],\n",
    "    [0.2, 0.2, 0.4],\n",
    "    [0.5, 0.3, 0.3],\n",
    "])\n",
    "y_train = torch.tensor([0, 1, 0, 1, 2])\n",
    "y_pred_expected = torch.tensor([1, 0, 0])\n",
    "_, y_pred = predict_labels(dists, y_train, k=3)\n",
    "correct = y_pred.tolist() == y_pred_expected.tolist()\n",
    "print('Correct: ', correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMBf1Z6VF9hx"
   },
   "source": [
    "Then we use an example from the TinyPlaces dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1640850754796,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "zTa7xowOfWz-",
    "outputId": "707724ca-8cf0-46e3-bb64-99b1eda20adc"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "\n",
    "y_pred_test = classifier.predict(x_test[:1], k=10).squeeze()\n",
    "\n",
    "correct = y_pred_test == y_test[0]\n",
    "print('Correct: ', correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tgNeDX0fW0A"
   },
   "source": [
    "## Image Classification\n",
    "We can now use the exact same KNN code to perform image classification on TinyPlaces!\n",
    "\n",
    "Now lets put everything together and test our K-NN clasifier on the full TinyPlaces, using k=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1651,
     "status": "ok",
     "timestamp": 1640850775496,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "W5GVNBh0ySGN",
    "outputId": "0526b0f5-93a4-44be-ea3f-cede857870b2"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQwHpcPrIF5u"
   },
   "source": [
    "Now lets increase to k=10. You should see a slightly higher accuracy than k=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2237,
     "status": "ok",
     "timestamp": 1640850780607,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "_a4zwcTe0PIK",
    "outputId": "6c025913-e452-493a-8015-d54cf443a1aa"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNyZLRmaIgT0"
   },
   "source": [
    "## Cross-validation\n",
    "We have not implemented the full k-Nearest Neighbor classifier. We will use **cross-validation** to set this hyperparameter in a more principled manner.\n",
    "\n",
    "In the file `knn.py`, implement the function `knn_cross_validate` to perform cross-validation on k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126850,
     "status": "ok",
     "timestamp": 1640850912272,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "pA5MrumnLk5B",
    "outputId": "9b9e4ce9-849f-4b77-8d88-a5a3e2fa0634"
   },
   "outputs": [],
   "source": [
    "from knn import knn_cross_validate\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "k_to_accuracies = knn_cross_validate(x_train, y_train, num_folds=5)\n",
    "\n",
    "for k, accs in sorted(k_to_accuracies.items()):\n",
    "  print('k = %d got accuracies: %r' % (k, accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1640850933525,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "vMtPikIsNxl2",
    "outputId": "c722c9e6-279b-421f-fdd0-72fb62e22539"
   },
   "outputs": [],
   "source": [
    "ks, means, stds = [], [], []\n",
    "torch.manual_seed(0)\n",
    "for k, accs in sorted(k_to_accuracies.items()):\n",
    "  plt.scatter([k] * len(accs), accs, color='g')\n",
    "  ks.append(k)\n",
    "  means.append(statistics.mean(accs))\n",
    "  stds.append(statistics.stdev(accs))\n",
    "plt.errorbar(ks, means, yerr=stds)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.title('Cross-validation on k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ3Ue0bxmObU"
   },
   "source": [
    "Now we can use the results of cross-validation to select the best value for k, and rerun the classifier on our full set of training examples. \n",
    "(I can get an accuracy of 70%. Try to beat me!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1850,
     "status": "ok",
     "timestamp": 1640850969868,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "NBZfp1UtWyoG",
    "outputId": "d6f54eb6-d427-4f99-b737-71f213191587"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "from knn import knn_get_best_k\n",
    "\n",
    "best_k = 1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "best_k = knn_get_best_k(k_to_accuracies)    \n",
    "print('Best k is ', best_k)\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bn7OkGzkV5YO"
   },
   "source": [
    "## Feature Extraction\n",
    "Now, instead of using raw pixel values as input, we will extract the features from the images. We have implemented this for you. Just set ``feature`` to ``True`` when calling tinyplaces. We use histograms of colors as features. You should go through the codes in data.py and understand how feature extraction goes. \n",
    "\n",
    "Likewise, we will first perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63112,
     "status": "ok",
     "timestamp": 1640851520782,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "uuu4_Fa9NtAj",
    "outputId": "062f1755-e985-42c3-ca8e-e9dfd411c4a7"
   },
   "outputs": [],
   "source": [
    "import cs188\n",
    "from knn import knn_cross_validate\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, feature=True)\n",
    "\n",
    "k_to_accuracies = knn_cross_validate(x_train, y_train, num_folds=5)\n",
    "\n",
    "for k, accs in sorted(k_to_accuracies.items()):\n",
    "  print('k = %d got accuracies: %r' % (k, accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX03FrqWYI3f"
   },
   "source": [
    "Using features, I can achieve 74% accuracy. What about you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12025,
     "status": "ok",
     "timestamp": 1640851637192,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "VhStLxFFs-d1",
    "outputId": "1bb7e1cb-3702-459d-ae66-ea6233288bb2"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "from knn import knn_get_best_k\n",
    "\n",
    "best_k = 1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "best_k = knn_get_best_k(k_to_accuracies)    \n",
    "print('Best k is ', best_k)\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, feature=True)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ1Fm29qYhg_"
   },
   "source": [
    "### Write down your understanding of feature extraction, and how it affects the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWHOIOqlY66T"
   },
   "source": [
    "**Your Answer**: [Write down your answer here]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOkquL-BZGgl"
   },
   "source": [
    "# KNN (Multi-Class Classification)\n",
    "\n",
    "Now we we will switch to multi-class classification. Instead of classifying indoor-outdoor scenes, we will have all the 20 sub-categories for classification.\n",
    "\n",
    "You do not need to change your implementations here. Just set ``binary`` to ``False`` when calling tinyplaces loader. \n",
    "\n",
    "We will also go through cross validation first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122775,
     "status": "ok",
     "timestamp": 1640852505454,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "QN_F8pViCORV",
    "outputId": "4cdd513f-d027-4f51-a52e-cdfd2eab956f"
   },
   "outputs": [],
   "source": [
    "import cs188\n",
    "from knn import knn_cross_validate\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, binary=False)\n",
    "\n",
    "k_to_accuracies = knn_cross_validate(x_train, y_train, num_folds=5)\n",
    "\n",
    "for k, accs in sorted(k_to_accuracies.items()):\n",
    "  print('k = %d got accuracies: %r' % (k, accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HJzHwlSbzak"
   },
   "source": [
    "For multi-class classification, I can get 17% accuracy. What about you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2545,
     "status": "ok",
     "timestamp": 1640852660488,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "YLBFcnQ_CORZ",
    "outputId": "6e175aa6-531c-4084-b88b-52c458a3561d"
   },
   "outputs": [],
   "source": [
    "from knn import KnnClassifier\n",
    "from knn import knn_get_best_k\n",
    "\n",
    "best_k = 1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "best_k = knn_get_best_k(k_to_accuracies)    \n",
    "print('Best k is ', best_k)\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, binary=False)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1640853534277,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "9-OTAZ6WdcWi",
    "outputId": "6fc50447-5cb4-4b2f-83a3-6a25186b1f59"
   },
   "outputs": [],
   "source": [
    "indices = classifier.retrieval(x_test[:1], k=20)\n",
    "\n",
    "classes_list = ['bathroom', 'bedroom', 'bookstore', 'classroom', 'dining_room', 'food_court', 'kitchen', 'lobby', 'living_room', 'office', 'baseball_field', 'bridge', 'campsite', 'canyon', 'coast', 'fountain', 'highway', 'playground', 'mountain', 'rainforest']\n",
    "print (\"this is the original sample from the test set of %s scene\"%classes_list[y_test[0]])\n",
    "plt.imshow(cs188.tensor_to_image(x_test[0]))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "for idx in indices:\n",
    "  samples.append(x_train[idx].squeeze())\n",
    "  labels.append(y_train[idx].squeeze())\n",
    "\n",
    "\n",
    "print (\"this is the most relevant images from the training set to an %s sample\"%classes_list[y_test[0]])\n",
    "img = torchvision.utils.make_grid(samples, nrow=5)\n",
    "plt.imshow(cs188.tensor_to_image(img))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print (\"and their labels\")\n",
    "print ([classes_list[label] for label in labels])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "knn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
