{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcJK3kXl--c3"
   },
   "source": [
    "# CS188 Assignment 1-2: Linear Regression & Logistic Regression & Softmax Regression\n",
    "\n",
    "Before we start, please put your name and UD in following format\n",
    "\n",
    ": Firstname LASTNAME, #00000000   //   e.g.) Yining Hong, #000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sA2iBcm_cPb"
   },
   "source": [
    "**Your Answer:**   \n",
    "Your NAME, #XXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EylwToVNld4u"
   },
   "source": [
    "In this notebook you will implement a Linear Regression & Logistic Regression on the tinyplaces dataset you created.\n",
    "\n",
    "Recall that the Linear Regression does the following:\n",
    "- Use linear function to model the relationship between an input and an output\n",
    "- Use loss function to minimize the weight and bias of the linear function. In this assignment, we use Mean Squared Error as the loss function.\n",
    "\n",
    "Logistic Regression takes a step further by adding a logistic function to the linear output. Here, we use Cross-Entropy Loss to optimize logistic regression.\n",
    "\n",
    "Logistic Regression and Linear regression are for binary classification. For multi-class classification, we use Softmax Regression. Softmax Regression is an extension for linear regression where we add a softmax function to the linear output, and use NLL-loss to optimize.\n",
    "\n",
    "\n",
    "The goals of this exercise are to go through a simple example of the data-driven image classification pipeline, and also to practice writing efficient, vectorized code in [PyTorch](https://pytorch.org/).\n",
    "\n",
    "you may not use any functions from torch.nn or torch.nn.functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrEwOpXb9Gh"
   },
   "source": [
    "# Setup Code\n",
    "Before getting started we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook.\n",
    "\n",
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1640979272137,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "73cuTs3re6wg",
    "outputId": "e199a133-e189-4bdb-c689-9b869e2628bb"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnf0BfHZfWzO"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20474,
     "status": "ok",
     "timestamp": 1640979299640,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "VxbQtNB6fWzO",
    "outputId": "c11ad14c-2412-4220-a6ae-db43c342fd26"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1640979346873,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "kfzFXbiEfWzS",
    "outputId": "49b7d39c-19da-4639-f68f-ac368559da15"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
    "# Example: If you create a 188 folder and put all the files under A1 folder, then '188/Assignment1'\n",
    "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '188/Assignment1'\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Assignment1'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY_PV4eQfWzU"
   },
   "source": [
    "Once you have successfully mounted your Google Drive and located the path to this assignment, run th following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n",
    "\n",
    "```\n",
    "Hello from regression.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the file `pytorch101.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5893,
     "status": "ok",
     "timestamp": 1640979354422,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "VGbUf6nTfWzV",
    "outputId": "bf6ede31-8c59-436e-a520-0640113129d4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "import time, os\n",
    "os.environ[\"TZ\"] = \"US/Eastern\"\n",
    "time.tzset()\n",
    "\n",
    "from regression import hello\n",
    "hello()\n",
    "\n",
    "path = os.path.join(GOOGLE_DRIVE_PATH, 'regression.py')\n",
    "edit_time = time.ctime(os.path.getmtime(path))\n",
    "print('regression.py last edited on %s' % edit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emQnvtnFeX1H"
   },
   "source": [
    "## Setup code\n",
    "Run some setup code for this notebook: Import some useful packages and increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tf64a0TS8zh7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cs188\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGCZcPebKi_"
   },
   "source": [
    "We will run the codes on GPU. Go to:\n",
    "Runtime->Change Runtime Type->Hardware Accelerator->GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1640979545670,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "DrIsTFvsbMgU",
    "outputId": "055c8fb1-1ba5-44f8-ec82-42e6f6cffe10"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available:\n",
    "  print('Good to go!')\n",
    "else:\n",
    "  print('Please set GPU via Edit -> Notebook Settings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M0pmnWwgFu5"
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "We will implement linear regression step by step. Remember that for linear regression:\n",
    "\n",
    "$$y = WX+b$$\n",
    "\n",
    "In our case, $X$ is the 3072-dim image pixels. Thus, the weight $W$ should be compatible with the dim of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOZTkdiSmUFc"
   },
   "source": [
    "## Initialize Weights and Biases and Implement Linear Function\n",
    "You will implement the linear function and the predict function for the Linear Classification class in `regression.py`.\n",
    "\n",
    "If the prediction score > 0.5, we consider the image to be of outdoor category. Otherwise, we consider it to be indoor category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11055,
     "status": "ok",
     "timestamp": 1640979568618,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "oHq2bs_MnqVM",
    "outputId": "67caa980-969c-4170-d730-2eeb037b45ab"
   },
   "outputs": [],
   "source": [
    "from regression import *\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train, y_train, x_val, y_val = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, use_gpu=True)\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "y_pred = regression_model.predict(x_train).squeeze()\n",
    "print (\"output size %s\" %(str(y_pred.size())))\n",
    "print (\"train accuracy\")\n",
    "acc = regression_model.check_accuracy(x_train, y_train)\n",
    "print (\"validation accuracy\")\n",
    "acc = regression_model.check_accuracy(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUqwuvDZQ1G_"
   },
   "source": [
    "Since we initialize the weights and biases to be zero, the outputs should also be zero. Therefore, you should get 50% accuracy here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbdallziXnq_"
   },
   "source": [
    "## Find the best W using one-step calculation\n",
    "\n",
    "As taught in class, for linear regression, the best weight W (or $\\hat{\\beta}$) can be calculated directly using the training data. Now, implement the calculate_param function in `regression.py` Linear Regression class to modify the weight W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5590,
     "status": "ok",
     "timestamp": 1640979577140,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "zyVEya4BGmF7",
    "outputId": "141907bc-1ec2-49e3-9ce5-834e84aeb195"
   },
   "outputs": [],
   "source": [
    "from regression import *\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train, y_train, x_val, y_val = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "regression_model.calculate_param(x_train, y_train)\n",
    "regression_model.b = regression_model.b.cpu()\n",
    "\n",
    "y_pred = regression_model.predict(x_train).squeeze()\n",
    "print (\"output size %s\" %(str(y_pred.size())))\n",
    "print (\"train accuracy\")\n",
    "acc = regression_model.check_accuracy(x_train, y_train)\n",
    "print (\"validation accuracy\")\n",
    "acc = regression_model.check_accuracy(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9JPTFVGS8Cm"
   },
   "source": [
    "I can get ~80% train accuracy and ~70% validation accuracy. You should get the similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHkuvdr_1HqC"
   },
   "source": [
    "## Find the best W by gradient descent\n",
    "\n",
    "Previously, we could calculate the estimated W given the input and output. This is because the linear function is simple to optimize. However, a more general way to find the best parameters is to using gradient descent, as taught in class.\n",
    "\n",
    "For gradient descent, we need to:\n",
    "\n",
    "    Compute the losses between the predicted labels and ground-truth labels.\n",
    "    Back-propagate the losses to get the gradients of the parameters.\n",
    "    Get the parameters for the next iteration by subtracting the gradient      mutlipled by learning rate.\n",
    "\n",
    "You will only need to implement the first step as we have implemented the rest of the steps for you.\n",
    "\n",
    "### Compute losses\n",
    "\n",
    "We can compare the predictions with the actual targets, using the following method:\n",
    "\n",
    "    Calculate the difference between the two matrices (preds and targets).\n",
    "    Square all elements of the difference matrix to remove negative values.\n",
    "    Calculate the average of the elements in the resulting matrix.\n",
    "\n",
    "The result is a single number, known as the mean squared error (MSE).\n",
    "\n",
    "Please implement this in the ``get_loss() function``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1640979665246,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "ujU8bWch4EmK",
    "outputId": "517ddc36-db69-4b02-9ed5-4afc7d0aae2c"
   },
   "outputs": [],
   "source": [
    "from regression import *\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train, y_train, x_val, y_val = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, use_gpu=True)\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "y_pred = regression_model.predict(x_train).squeeze()\n",
    "loss = regression_model.get_loss(y_pred, y_train)\n",
    "print (\"loss is %f\"%loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3S4Fj63lhYf"
   },
   "source": [
    "The resulting number is called the loss, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model.\n",
    "\n",
    "Since we initialize the weight as zero, all outputs are zero. Therefore, the loss is 0.5 here. (Because it is the mean of the squared loss of the differences between preds and targets. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDiVTn3ukV6G"
   },
   "source": [
    "## Compute Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRjjnkRClki7"
   },
   "source": [
    "With PyTorch, we can automatically compute the gradient or derivative of the loss w.r.t. to the weights and biases, because they have requires_grad set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "error",
     "timestamp": 1640979683347,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "IkrTKNIjke_S",
    "outputId": "b79ba342-fde4-4012-bed0-dc595764b6c2"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCiDB-5Cln7_"
   },
   "source": [
    "The gradients are stored in the .grad property of the respective tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1640979685770,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "jjK93S8FlvEg",
    "outputId": "e24a21c8-5309-4ea2-e0d8-2969d875b262"
   },
   "outputs": [],
   "source": [
    "# Gradients for weights\n",
    "print(regression_model.W.grad)\n",
    "# Gradients for bias\n",
    "print(regression_model.b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdZbRpoamSiG"
   },
   "source": [
    "\n",
    "## Adjust weights and biases using gradient descent\n",
    "\n",
    "We'll reduce the loss and improve our model using the gradient descent algorithm, by adjust the weights by subtracting a small quantity proportional to the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_jo70CemcI-"
   },
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    regression_model.W -= regression_model.W.grad * 1e-4\n",
    "    regression_model.b -= regression_model.b.grad * 1e-4\n",
    "    regression_model.W.grad.zero_()\n",
    "    regression_model.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnOciI6smquC"
   },
   "source": [
    "We now calculate the new loss in the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1640979690310,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "bIcbKImMmto2",
    "outputId": "49ce1cd8-ef0c-4357-ab94-0046e81d6beb"
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "y_pred = regression_model.predict(x_train).squeeze()\n",
    "loss = regression_model.get_loss(y_pred, y_train)\n",
    "acc = regression_model.check_accuracy(x_val, y_val)\n",
    "print (\"new loss is %f\"%loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13Hc7bCbqGQ1"
   },
   "source": [
    "\n",
    "## Train for multiple epochs\n",
    "\n",
    "To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 51057,
     "status": "error",
     "timestamp": 1640979743778,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "o75fpy7hqOag",
    "outputId": "1473a69e-f56a-4544-ab6e-17e5f1b7fc74"
   },
   "outputs": [],
   "source": [
    "from regression import *\n",
    "\n",
    "x_train, y_train, x_val, y_val = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, use_gpu=True)\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "losses = []\n",
    "\n",
    "linear_val_accs = []\n",
    "best_W = None\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(500000):\n",
    "    y_pred = regression_model.predict(x_train).squeeze()\n",
    "    acc = regression_model.check_accuracy(x_val, y_val, quiet=True)\n",
    "    linear_val_accs.append(acc)\n",
    "\n",
    "    loss = regression_model.get_loss(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_W = regression_model.W\n",
    "      best_acc = acc\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "      print (\"%d/500000 iteration\"%i)\n",
    "      print (\"validation accuracy is %f\"%acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      regression_model.W -= regression_model.W.grad * 1e-4\n",
    "      regression_model.b -= regression_model.b.grad * 1e-4\n",
    "      regression_model.W.grad.zero_()\n",
    "      regression_model.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDFQtmTzq0hF"
   },
   "source": [
    "I can get ~80% accuracy. Can you beat me?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MbmFMyiucyD"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_70rF9j9t9ab"
   },
   "source": [
    "In `regression.py`, please implement the following functions:\n",
    "\n",
    "Logistic Regression extends Linear Regression by adding a sigmoid function:\n",
    "$$\\frac{1}{1+e^{-x}}$$\n",
    "Implement the sigmoid function and the predict function of the Logistic Regression class. \n",
    "Then, implement the cross entropy loss :\n",
    "$$-{(y\\log(p) + (1 - y)\\log(1 - p))}$$\n",
    "\n",
    "We will run the results of logistic regression below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 62676,
     "status": "error",
     "timestamp": 1640979810135,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "cgA4LnZit0Qn",
    "outputId": "8da39aef-a1a7-4f4a-d834-190e6d42d26a"
   },
   "outputs": [],
   "source": [
    "from regression import *\n",
    "\n",
    "x_train, y_train, x_val, y_val = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, use_gpu=True)\n",
    "\n",
    "regression_model = LogisticRegression()\n",
    "\n",
    "losses = []\n",
    "logistic_val_accs = []\n",
    "best_W = None\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(500000):\n",
    "    y_pred = regression_model.predict(x_train).squeeze()\n",
    "    acc = regression_model.check_accuracy(x_val, y_val, quiet=True)\n",
    "    logistic_val_accs.append(acc)\n",
    "\n",
    "    loss = regression_model.get_loss(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_W = regression_model.W\n",
    "      best_acc = acc\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "      print (\"%d/500000 iteration\"%i)\n",
    "\n",
    "      print (\"test accuracy is %f\"%acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      regression_model.W -= regression_model.W.grad * 1e-4\n",
    "      regression_model.b -= regression_model.b.grad * 1e-4\n",
    "      regression_model.W.grad.zero_()\n",
    "      regression_model.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaLMch19sKnP"
   },
   "source": [
    "I can get ~83% accuracy. Can you beat me?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtnMWgaKs6Yf"
   },
   "source": [
    "### Visualize the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1640979855410,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "IziBkrSms-tH",
    "outputId": "4d6bc960-63ee-4af3-8484-56c0d1d8f146"
   },
   "outputs": [],
   "source": [
    "plt.plot(linear_val_accs, label='linear regression')\n",
    "plt.plot(logistic_val_accs, label='logistic regression')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHa3Fojwcblj"
   },
   "source": [
    "### Visualize the weights\n",
    "\n",
    "Visualize the learned weights for each class. If your implementation is right, the visualization should be close to the average of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1640979864494,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "DXFeNdxPcbln",
    "outputId": "bc26691a-bf20-4f86-db2a-a7953d0e0dba"
   },
   "outputs": [],
   "source": [
    "w = best_W.reshape(3, 32, 32)\n",
    "w = w.transpose(0, 2).transpose(1, 0)\n",
    "\n",
    "w_min, w_max = torch.min(w), torch.max(w)\n",
    "\n",
    "wimg = 255.0 * (w - w_min) / (w_max - w_min)\n",
    "\n",
    "plt.imshow(wimg.type(torch.uint8).cpu())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB66S3Rhlq2i"
   },
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJQ5VAayuHBT"
   },
   "source": [
    "You need to implement the following functions in `regression.py`:\n",
    "\n",
    "Softmax is a multi-class classification extension from Logistic Regression . Implement the softmax function:\n",
    "$$\\frac{e^{z_{i}}}{\\sum_{j=1}^K e^{z_{j}}} \\ \\ \\ for\\ i=1,2,\\dots,K$$\n",
    "\n",
    "For softmax regression, the loss function is the NLL (negative log likelihood) loss. Implement the loss function :\n",
    "$$-{\\log(p(y))}$$\n",
    "Here $p(y)$ is a scaler instead of vector. It is the value of the single dimension where the ground truth $y$ lies. It is thus equivalent to cross entropy\n",
    "\n",
    "Implement the predict function in Softmax Regression class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "executionInfo": {
     "elapsed": 131160,
     "status": "error",
     "timestamp": 1640980002910,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "GRJrc4kll89U",
    "outputId": "6a8fde89-e9d4-4382-ce52-a8b7f57e8256"
   },
   "outputs": [],
   "source": [
    "from regression import *\n",
    "\n",
    "x_train, y_train, x_test, y_test = cs188.data.tinyplaces(GOOGLE_DRIVE_PATH, binary=False, use_gpu=True)\n",
    "\n",
    "regression_model = SoftmaxRegression()\n",
    "\n",
    "losses = []\n",
    "\n",
    "best_W = None\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(1000000):\n",
    "    y_pred = regression_model.predict(x_train).squeeze()\n",
    "    acc = regression_model.check_accuracy(x_test, y_test, quiet=True)\n",
    "\n",
    "    loss = regression_model.get_loss(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_W = regression_model.W\n",
    "      best_acc = acc\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "      print (\"%d/500000 iteration\"%i)\n",
    "\n",
    "      print (\"test accuracy is %f\"%acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      regression_model.W -= regression_model.W.grad * 1e-4\n",
    "      regression_model.b -= regression_model.b.grad * 1e-4\n",
    "      regression_model.W.grad.zero_()\n",
    "      regression_model.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGJbGQLHxTCi"
   },
   "source": [
    "### Visualize Weight\n",
    "\n",
    "Now, visualize the weight for each class. If your implementation is right, the weight of each class should be equivalent to the average of the images of that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1640980006617,
     "user": {
      "displayName": "Yining Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiE5-ME9XjROxPvTyDrxx-4hWSfcllxppcLuf45dQ=s64",
      "userId": "17790273499144031239"
     },
     "user_tz": 480
    },
    "id": "-AIjcLjnqo7O",
    "outputId": "94cdd8ef-ec6f-4029-f92f-a3acae9957f8"
   },
   "outputs": [],
   "source": [
    "w = best_W.reshape(3, 32, 32, 20)\n",
    "w = w.transpose(0, 2).transpose(1, 0)\n",
    "\n",
    "w_min, w_max = torch.min(w), torch.max(w)\n",
    "\n",
    "classes = ['bathroom', 'bedroom', 'bookstore', 'classroom', 'dining_room', 'food_court', 'kitchen', 'lobby', 'living_room', 'office', 'baseball_field', 'bridge', 'campsite', 'canyon', 'coast', 'fountain', 'highway', 'playground', 'mountain', 'rainforest']\n",
    "for i in range(20):\n",
    "  plt.subplot(4,5, i + 1)\n",
    "\n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "  plt.imshow(wimg.type(torch.uint8).cpu())\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thUs0hJeul73"
   },
   "source": [
    "# What's the difference between Linear Regression, Logistic Regression and Softmax Regression? (Write down your answer below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yDmHJLjv5hF"
   },
   "source": [
    "**Your Answer**: [fill in the answer here]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
